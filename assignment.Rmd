---
title: 'Homework #3'
author: "Michael Munguia"
date: "10/17/2021"
output: html_document
---

```{r setup, include=FALSE,}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library(tidyverse)

loans <- read_csv(
  "https://raw.githubusercontent.com/Izote/DATA622-Assignment-3/main/Loan_approval.csv", show_col_types = FALSE
  )
```


# Section 1: Exploratory Data Analysis (EDA)

```{r}
cont_vars <- c(
  "ApplicantIncome", "CoapplicantIncome", "LoanAmount", "Loan_Amount_Term"
  )

disc_vars <- c(
  "Gender", "Married", "Dependents", "Education", "Self_Employed", 
  "Property_Area", "Credit_History"
  )
```

Given that our target variable is an approved loan status ($Y$ value for $Loan_Status$), the very first observation we might make is that about 69% of the applicants represented in the data set were applicants with an approved loan. Surveying the continuous variables available, we see that applicant/co-applicants' incomes and loan amounts share similarly right-skewed distributions, with the two income variables being more extreme in their skew. These three variables share a sense of scale (i.e. they refer to monetary amounts and two are incomes) whereas the loan term is on a different scale and measurement (months) along with its displaying a left-skewed distribution.

It is notable that the variable representing the income of a co-applicant, `CoapplicantIncome`, is an untidy variable - it represents both whether a co-applicant was involved in the process *and* their income. There is insufficient context to understand how to best utilize this variable. For example, a co-applicant may be a married spouse, blood relative or even a domestic partner. We may be able to intuit and better engineer features based on this information, but without further context we cannot know for certain how to handle unmarried applicants vis-a-vis their `CoapplicantIncome` value.

```{r}
show_dist <- function(df) {
  df %>% 
    ggplot(aes(value, color = Loan_Status)) +
    geom_freqpoly(bins = 30) +
    facet_wrap("name", scales = "free") +
    scale_x_continuous(labels = scales::comma_format())
}

pivot_longer(loans, all_of(cont_vars)) %>% show_dist()
```

Knowing that we will be utilizing linear discriminant analysis downstream, it's important to identify that, with the exception of `Loan_Amount_Term`, we may be able to apply a transformation to force these variables into a more Gaussian shape. In fact, `Loan_Amount_Term` should truly be considered a discrete variable as it seems to follow fixed 12-day increments. When visualized, we see that nearly all the applications were for 360 day loans.

```{r}
loans <- mutate(loans, across("Loan_Amount_Term", as.character))

loans %>% 
  ggplot(aes(x = Loan_Amount_Term, fill = Loan_Status)) +
  geom_bar(position = "dodge")
```

Taking the remaining data set and visualizing loan status for each discrete variable, we can see some interesting trends. Credit history seems to play a crucial role, with applicants meeting guidelines (`Credit_History = 1`) showing only 7 denied-loans across a data set of 614 applicants. A majority proportion of the approved-loan group have no dependents, graduated from college and are male. That last feature initially gave some pause as it may have been indicative of a discriminatory bias, however, it appears that an overwhelming 80% of applicants identify as male.

```{r}
long_disc <- loans %>% 
  mutate(across("Credit_History", as.character)) %>% 
  select(all_of(c(disc_vars, "Loan_Status"))) %>% 
  pivot_longer(all_of(disc_vars)) %>% 
  count(name, value, Loan_Status) %>% 
  group_by(name) %>% 
  mutate(total = sum(n)) %>% 
  ungroup() %>% 
  mutate(pct = n / total)


long_disc %>% 
  ggplot(aes(x = value, y = pct, fill = Loan_Status)) +
  geom_col(position = "dodge") +
  scale_y_continuous(breaks = seq(0, 1, 0.1), labels = scales::percent_format(1)) +
  facet_wrap("name", scales = "free")
```

Married applicants make up a majority in both groups, though married applicants make up a greater portion of approved-loan applicants across the whole data set. In terms of sheer count, however, it should be noted there are nearly twice as many married applicants than single ones. While different types of property area are well represented across both groups, there is some differentiation in how they are represented within each group. The self-employed are less represented in the approved-loan group, though this may be an artifact of the lack of representation of many self-employed applicants to begin with - they make up only 13% of applicants (or a count of 82). 

# Section 2: Linear Discriminant Analysis

Our first goal is to create a model using Linear Discriminant Analysis (LDA). In order to achieve this, as stated earlier, we will need to assume a Gaussian distribution across predictors. This implicitly guides us towards the continuous variables that showed skewed distributions during EDA. 

As such, we will conduct some transformations on these variables to help us achieve a (closer) to Gaussian distribution for these continuous variables. The variable `CoapplicantIncome` was not included in this work, due to the untidy aspects of its recording - which would only become exacerbated as the distribution becomes bimodal when employing `log` transformations. As discussed, the categorical variable `LoanAmount` will not be used in this scenario either. The new distributions can be seen below - while imperfect, they are far closer to a normal/Gaussian distribution than before.

```{r}
lda_cont <- c("ApplicantIncome", "LoanAmount")

loans %>% 
  mutate(across(lda_cont, ~ scale(log(.))[ , 1])
    ) %>% 
  pivot_longer(lda_cont) %>% 
  show_dist()
```

The transformations will not be directly applied to the data set itself as that would make potential changes more cumbersome to deal with down the road. Instead, the data will be divided into randomly selected training, validation and test data sets and the transformations will be part of the modeling function's call.

```{r}
set.seed(3)

training <- slice_sample(loans, prop = 0.70)

remaining <- anti_join(loans, training, by = "Loan_ID")
validation <- slice_sample(remaining, prop = 0.5)
test <- anti_join(remaining, validation, by = "Loan_ID")

lda_mod <- MASS::lda(
  Loan_Status ~ log(ApplicantIncome) + log(LoanAmount), data = training
  )
```

Through some initial experimentation, a threshold was settled upon to determine whether an applicant would be rejected for a loan. This was necessary because, due to the unbalanced priors, a "plain" LDA model would always classify our data as `Loan_Status = "Y"`, which is not remotely useful. In this way, any prediction where the posterior probability was greater/equal to 80% for an approval was classed as such.

```{r}
set_preds <- function(df, preds, threshold) {
  df <- df %>% 
    mutate(
      Posterior = preds$posterior[, "Y"],
      Predicted_Status = if_else(Posterior <= threshold, "Y", "N"),
      Score = Loan_Status == Predicted_Status
    )
  
  mean(df$Score, na.rm = TRUE)
}

validation_preds <- predict(lda_mod, newdata = validation)
test_preds <- predict(lda_mod, newdata = test)
```


```{r}
set_preds(validation, validation_preds, 0.80)
```

This produced a model with an accuracy of about 65% against the validation data, which is a modest improvement from the null-model.

```{r}
set_preds(test, test_preds, 0.80)
```

This decreases further with the test data, though we still float at about 59% accuracy - again, a modest improvement on the null-model.

# Section 3: K-nearest Neighbors (KNN)

Utilizing KNN requires a different setup in how the data is provided to `class::KNN` than we saw with `MASS::lda`. Recycling the training, validation and test split from before we simply modify the structure to facilitate using our next method. Additionally - the continuous predictors are scaled and centered in order to avoid differences of scale causing any one to dominate the results.

```{r}
knn_data <- map(
  list("train" = training, "val" = validation, "test" = test),
  ~ .x %>% 
    select(all_of(
      c("ApplicantIncome", "LoanAmount", "Credit_History", "Loan_Status")
      )) %>% 
    drop_na() %>% 
    mutate(across(c("ApplicantIncome", "LoanAmount"), ~ scale(.)[ ,1]))
)

```

We'll want to land on a value for $k$ and doing so is much easier by mapping our function and visualizing the results.

```{r}
do_knn <- function(test_set, k_val) {
  class::knn(
    train = select(knn_data[["train"]], -Loan_Status),
    cl = knn_data[["train"]]$Loan_Status,
    test = select(test_set, -Loan_Status),
    k = k_val
  )
}

neighbors <- seq(1, 10)

val_scores <- map_dbl(
  neighbors,
  ~ mean(do_knn(knn_data[["val"]], .x) == knn_data[["val"]]$Loan_Status)
  )
```


```{r}
tibble(k = neighbors, accuracy = val_scores) %>% 
  ggplot(aes(k, accuracy)) +
  geom_point(size = 2) +
  geom_line(linetype = 2) +
  labs(x = "k-Neighbor(s)", y = "Accuracy") +
  scale_x_continuous(breaks = neighbors) +
  scale_y_continuous(n.breaks = 8, labels = scales::percent_format(1))
```

Based on this output, it appears that the best choice as far this KNN model goes is to utilize $k=5$. Doing so with the test data set achieves an accuracy of about 70%. 

```{r}
mean(do_knn(knn_data[["test"]], 5) == knn_data[["test"]]$Loan_Status)
```

# Section 4: Decision trees



# Section 5: Random forests



# Section 6: Model performance


